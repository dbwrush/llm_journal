# LLM Journal Configuration

[server]
port = 3000
host = "0.0.0.0"

[files]
tokens_file = "tokens.json"

[auth]
# Session duration in seconds (1 year)
session_duration_seconds = 31536000
# Passcode expiration in seconds (10 minutes)  
passcode_expiration_seconds = 600

[journal]
# Directory to store journal files
journal_directory = "journal_entries"
# Time to run nightly processing (24-hour format)
processing_time = "03:00"
# Time to generate daily prompts (24-hour format)
prompt_generation_time = "06:00"
# Maximum number of prompts to generate per day
max_prompts_per_day = 3

[llm]
# Model identifier for HuggingFace Hub
model_name = "microsoft/gpt-oss-20b"
# Maximum tokens for summaries
summary_max_tokens = 100
# Maximum tokens for prompts
prompt_max_tokens = 150
# Use GPU acceleration (requires CUDA)
use_gpu = true
